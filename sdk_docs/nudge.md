- Thaler and Sunstein [2008] define a nudge as “any aspect of the choice architecture that alters people’s behavior in a predictable way without forbidding any options or significantly changing their economic incentives.”
- Dimensions
    - Information
        - Definition
            - The provision of information aims at mitigating negative effects of asymmetric information
            - and at overcoming availability and overconfidence biases that may lead to
            - suboptimal decisions. When providing information to create awareness about privacy
            - and security risks, system designers need to consider that users are subjected to different
            - cognitive biases, as discussed in Section 2.3. These biases can either be leveraged to
            - encourage beneficial behavior or need to be mitigated to prevent unintended outcomes.
            - Effective communication uses clear, short, and relevant messages to support users’
            - decision making.
        - Education during onboarding
        - Visibility of activity after actions are taken.
        - Notices
            - Using visual metaphors that align with the risks being taken.
            - Patil et al. [2011] enhanced the privacy settings dialog of an instant messenger to show the dominant disclosure settings of the user’s contacts.
            - Goecks and Mynatt [2005] visualize how many other community members have visited a website and if they blocked its cookies. They note that social navigation facilitates learning from the behavior of others but also carries the risk of just following what others do. They suggest engaging experts to help guide behavior.
    - Presentation
        - Framing
            - Overly warning users can help combat overconfidence.
        - Ordering
        - Saliency
            - Showing statistics of dangers can reinforce them (Pennsylvannia Transportation stats)
            - Forcing users to interact with a publisher name makes them more conscious of unknown sources
                - Bravo-Lillo et al. [2013] found that by making the name of the software publisher more salient in warning dialogs they could nudge people not to download suspicious software. While visual nudges were somewhat effective, the most effective nudges required users to interact with the salient publisher field. In this example, saliency is used without framing: the user’s attention is drawn to the publisher name without emphasizing risks or benefits of specific publishers.
                    - {{[[TODO]]}} read that article to learn what kind of interactions they're referring to.
    - Defaults
        - Goldstein et al. [2008] distinguish between [[mass defaults]], in which everyone gets the same default, and [[personalized defaults]] tuned to the user’s needs.
    - Incentives
        - Badges for desired behavior
            - Like the “mayor” badge for the most frequent guest of a restaurant on [[Foursquare]]
        - Multiple confirmations as punishment
        - [[red team]] your own users
            - 3.5.3. Incentives for Security. Incentives can be used to improve security as part of corporate
            - strategy. Users who handle email attachments in a careless manner can be
            - punished by restricting their email accounts to official communications. A user who is
            - more cautious with email attachments can be rewarded by allowing use of the corporate
            - account for personal emails. Brustoloni and Villamar´ın-Salom´on [2007] developed
            - audited security dialogs, in which users were held accountable for their decisions to
            - open email attachments. Those who took unjustified risks could be “subject to a variety
            - of sanctions, such as being unable to use the application for increasing periods of time,
            - having to pay increasing fines, or having to pass remedial training.” Their user study
            - found that these dialogs resulted in significantly fewer unjustified risks.
    - Reversibility and error resiliency
        - The goal is to allow users to recover from suboptimal decisions potentially caused by behavioral biases.
    - Timing
        - Each nudging technique may be needed at different points in time
        - Enforcing challenges during weird hours
            - Some tools provide nudges at specific times, when the user may be in a “hot” state
            - or under the influence of alcohol. Examples include the Social Media Sobriety Test
            - [Webroot 2010] and Mail Goggles for Gmail [Perlow 2008]. Both allow the user to
            - select specific hours of the week in which posting on social network sites or sending
            - emails is blocked until the user completes a dexterity or cognitive test, such as solving
            - a small math problem. Just-in-time notices providing relevant, clear, and contextual
            - information can help mitigate information asymmetries [Patrick and Kenny 2003;
            - Schaub et al. 2015]. Balebako et al. [2011] discuss further nudging techniques applied
            - at different points in time that also enable users to bypass them if neede
